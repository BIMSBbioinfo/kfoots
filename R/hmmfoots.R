#' Fit an hmm
#'
#' Fit to some count data an hmm where the emission probabilities are modelled as negative multinomials
#' @param counts matrix of non-negative integers. Columns represent datapoints and rows
#' 	dimensions 
#' @param models either the desired number of cluster, or a specific initial
#' 	value for the models. See the item \code{models} in the return values to see how the
#' 	parameters are specified
#' @param trans initial value for the transition probabilities. If not provided
#' 	equally likely transitions and fully connected markov model will be assumed.
#' @param tol error tolerance used when checking whether the parameters have
#' 	changed from one iteration to the next
#' @param maxiter maximum number of iterations in the EM algorithm
#' @param nbtype type of training for the negative binomial. Accepted types are:
#' 	\code{indep}, \code{dep}, \code{pois}. The first type corresponds to standard
#'.	maximum likelihood estimates for each parameter of each model, the second one
#'.	forces the \code{r} dispersion parameters of the negative multinomials to be the same
#' 	for all models, the third one forces \code{r} to be infinity, that is, every model
#' 	will be a Poisson distribution. Default is \code{indep}.
#' @param verbose print some output during execution
#' @param seqlens length of each run of adjacent datapoints
#' @return a list with the parameters of the fitted model:
#' 	\item{models}{a list containing the parameters of each component.
#' 		These are specified in another list with items \code{mu}, \code{r} and \code{ps}. \code{mu} and
#' 		\code{r} correspond to parameters \code{mu} and \code{size} in the R-function \code{\link{dnbinom}}.
#' 		Ps specifies the parameters of the multinomial and they sum up to 1.}
#' 	\item{mix_coeff}{the mixture coefficients of the mixture model}
#' 	\item{loglik}{the log-likelihood of the whole dataset.}
#'		\item{posteriors}{A matrix of size \code{length(models)*ncol(counts)} containing the posterior
#'			probability that a given datapoint is generated by the given mixture component}
#'		\item{converged}{\code{TRUE} if the algorithm converged in the given number of iterations, \code{FALSE} otherwise}
#'		\item{llhistory}{time series containing the log-likelihood of the
#'			whole dataset across iterations}
#'		\item{viterbi}{see output of \code{viterbi}}
#' @export
hmmfoots <- function(counts, k, trans=NULL, initP=NULL, tol = 1e-8, maxiter=100, nthreads=1,
	nbtype=c("indep","dep","pois"), init=c("rnd","counts","pca"), init.nlev=20, verbose=FALSE, seqlens=ncol(counts)){
	if (!is.matrix(counts))
		stop("invalid counts variable provided. It must be a matrix")
	#this will ensure efficiency of certain methods.
	#all floating point numbers will be "floored" (not rounded)
	storage.mode(counts) <- "integer"
	nbtype <- match.arg(nbtype)
	init <- match.arg(init)
	
	models <- NULL
	if (!is.numeric(k)){
		if (!is.list(k)){
			stop("Invalid input value for k, provide the desired number of models or a list with their initial parameters")
		}
		models <- k
		k <- length(models)
	}
	
	#rows of the count matrix represent positions of the footprint
	footlen <- nrow(counts)
	#columns of the count matrix represent genomic loci
	nloci <- ncol(counts)
	#precompute some stuff for optimization
	ucs <- mapToUnique(colSumsInt(counts, nthreads))
	mConst <- getMultinomConst(counts, nthreads)
	
	if (sum(seqlens) < nloci){
		warning("the provided seqlens do not add up to the total input length (ncol(counts)), adding a chunk to cover all the input")
		seqlens[length(seqlens)+1] <- nloci - sum(seqlens)
	} else if (sum(seqlens) > nloci){
		stop("invalid value for seqlens, the chunks sum up to more than the total input length")
	}
	
	if (is.null(models)){
		if (init=="rnd"){
			#get initial random models. Need to be kind-of similar to
			#the count matrix, cannot be completely random
			models <- rndModels(counts, k, bgr_prior=0.5, ucs=ucs, nbtype=nbtype, nthreads=nthreads)
		} else {
			init <- initAlgo(counts, k, nlev=init.nlev, nbtype=nbtype, nthreads=nthreads, axes=init, verbose=verbose)
			models <- init$models
			if (is.null(trans)) trans <- t(sapply(1:k, function(i) init$mix_coeff))
			if (is.null(initP)) initP <- matrix(nrow=k, rep(init$mix_coeff, length(seqlens)))
		}
	}
	if (is.null(trans)) {
		trans <- matrix(rep(1/k, k*k), ncol=k)
	} else if (is.matrix(trans) && (ncol(trans) != k || nrow(trans) != k)) {
		stop("'trans' must be a k*k transition matrix")
	} else if (!is.matrix(trans)){
		stop("'trans' must be a matrix")
	} 
	if (any(!compare(rowSums(trans), rep(1, k), tol))) stop("'trans' rows must sum up to 1")
	
	if (is.null(initP)) {
		initP <- matrix(rep(1/k, k*length(seqlens)), ncol=length(seqlens))
	} else if (is.vector(initP)&&!is.matrix(initP)&&length(seqlens)==1&&length(initP)==k){
		initP <- matrix(initP, ncol=1)
	} else if (is.matrix(initP) && (nrow(initP)!=k || ncol(initP)!=length(seqlens))){
		stop("invalid 'initP' matrix provided: one column per sequence and one row per model")
	} else if (!is.matrix(initP)){
		stop("'initP' must be a matrix, or a vector if there is only one sequence")
	}
	if (any(!compare(colSums(initP), rep(1, ncol(initP)), tol))) stop("'initP' columns must sum up to 1")
	
	
	#allocating memory
	posteriors <- matrix(0, nrow=k, ncol=nloci)
	lliks <- matrix(0, nrow=k, ncol=nloci)
	
	
	loglik <- NA
	converged <- FALSE
	llhistory <- numeric(maxiter)
	if (verbose) cat("starting main loop\n")
	for (iter in 1:maxiter){
		lLikMat(lliks=lliks, counts, models, ucs=ucs, mConst=mConst, nthreads=nthreads)
	
		res <- forward_backward(posteriors=posteriors, initP, trans, lliks, seqlens, nthreads=nthreads)
		
		new_loglik <- res$tot_llik
		new_trans <- res$new_trans
		new_initP <- res$new_initP

		if (verbose){
			cat("Iteration: ", iter, ", log-likelihood: ", new_loglik, "\n")
		}
		
		new_models <- fitModels(counts, posteriors, models, ucs=ucs, type=nbtype, nthreads=nthreads)
		
		if(iter!=1 && new_loglik < loglik && !compare(new_loglik, loglik, tol))
			stop(paste0("decrease in log-likelihood at iteration ",iter))
		
		if (all(compare(trans, new_trans,tol))){
			if (all(sapply(c(1:k), function(m) compareModels(models[[m]], new_models[[m]], tol)))){
				converged <- TRUE
			}
		}
		trans <- new_trans
		models <- new_models
		loglik <- new_loglik
		initP <- new_initP
		llhistory[iter] <- loglik
		if (converged){
			break
		}
	}
	if (!converged)
		warning(paste0("The algorithm did not converge after ", maxiter, " iterations (try to increase parameter maxiter)"))

	lLikMat(lliks=lliks, counts, models, ucs=ucs, mConst=mConst, nthreads=nthreads)
	viterbi_path <- viterbi(initP, trans, lliks, seqlens)
	
	for (i in seq_along(models)){
		names(models[[i]]$ps) <- rownames(counts)
	}
	
	#same as: clusters <- apply(posteriors, 2, which.max)
	clusters <- pwhichmax(posteriors, nthreads=nthreads)
	
	list(models=models, trans=trans, initP=initP, loglik = loglik,
	posteriors=posteriors, clusters=clusters, converged = converged, llhistory=llhistory[1:iter],
	viterbi=viterbi_path)
	
	
}

#' Get a steady state of a transition matrix.
#'
#' It should give a similar result as 
#' \code{rep(1/ncol(trans), ncol(trans)) trans^(big number)}
#' except that oscillating behaviours are averaged out.
#' @param trans transition matrix (rows are previous state, columns are next state)
#' @return a vector with a steady state distribution
#'	@export
getSteadyState <- function(trans){
	#first try with diagonalization, 
	#if it fails, exponentiate the trans matrix by a large number
	#etrans <- tryCatch(
	#	eigen(t(trans)),
	#	error=function(e) NULL)
	
	#ttrans2 ~ t(matpow(trans, Inf)) (it is transposed wrt trans)
	#ttrans2 <- tryCatch({
	#	evalues <- etrans$values
	#	for (i in seq_along(evalues)){
	#		if (abs(1-evalues[i]) < 1e-12){
	#			#eigenvalue has real part almost one and imaginary part almost 0, keep it
	#			evalues[i] <- 1
	#		} else {
	#			#eigenvalue less than one (in modulus), it will disappear, 
	#			#or with modulus one but complex, it will rotate all the time
	#			#in the gauss circle and average to 0.
	#			evalues[i] <- 0
	#		}
	#	}
	#	etrans$vectors %*% diag(evalues) %*% solve(etrans$vectors)
	#	},error=function(e) {
	#	#this is not very good when there are oscillatory behaviours...
	#	t(matpow(trans, 2^20))
	#})
	ttrans2 <- t(matpowtrans(trans, 2^30))
	as.numeric(ttrans2 %*% rep(1/ncol(trans), ncol(trans)))
	
}

#fast exponentiation algorithm,
#correct numerical fuzz by exploiting that 
#the rowSums sum up to 1
matpowtrans <- function(trans, pow){
	if (pow==1){
		trans
	}
	else if (pow %% 2 == 0){
		tmp <- matpowtrans(trans, pow/2)
		tmp <- tmp %*% tmp
		tmp/rowSums(tmp)
	}
	else {
		tmp <- trans %*% matpowtrans(trans, pow-1)
		tmp/rowSums(tmp)
	}
}

#fast exponentiation algorithm
matpow <- function(mat, pow){
	if (pow==1){
		mat
	}
	else if (pow %% 2 == 0){
		tmp = matpow(mat, pow/2)
		tmp %*% tmp
	}
	else {
		mat %*% matpow(mat, pow-1)
	}
}

generateHMMData <- function(n, models, trans, initP=getSteadyState(trans)){
	state <- sample(length(models), 1, prob=initP)
	mat <- matrix(0L, ncol=n, nrow=length(models[[1]]$ps))
	mat[,1] <- generateCol(models[[state]])
	for (i in 2:n){
		state <- sample(length(models), 1, prob=trans[state,])
		mat[,i] <- generateCol(models[[state]])
	}
	mat
}

exampleHMMData <- function(n=c(20000, 50000, 30000)){
	m1 = list(mu=40, r=0.4, ps=c(1,8,5,8,5,6,5,4,3,2,1))
	m2 = list(mu=20, r=2, ps=c(1,1,1,1,1,3,4,5,6,5,4))
	m1$ps = m1$ps/sum(m1$ps)
	m2$ps = m2$ps/sum(m2$ps)
	models <- list(m1, m2)
	
	trans = matrix(nrow=2, ncol=2, c(0.2, 0.6, 0.8, 0.4))
	
	
	do.call(cbind, lapply(n, function(currn) {generateHMMData(currn, models, trans)}))
}

